{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-going-beyond-the-sequential-model--keras-functional-api.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMrszcbdokOL5FRdF5kQaGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-with-python-francois-chollet/blob/7-advanced-deep-learning-best-practices/1_going_beyond_the_sequential_model_keras_functional_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZwz2w4AmLH4",
        "colab_type": "text"
      },
      "source": [
        "# Going beyond the Sequential model: the Keras functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOGAiLt4mOUq",
        "colab_type": "text"
      },
      "source": [
        "Until now, all neural networks introduced in this book have been implemented using the Sequential model. The Sequential model makes the assumption that the\n",
        "network has exactly one input and exactly one output, and that it consists of a linear stack of layers.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/sequential.png?raw=1' width='800'/>\n",
        "\n",
        "This is a commonly verified assumption; the configuration is so common that we’ve been able to cover many topics and practical applications in these pages so far using only the Sequential model class. But this set of assumptions is too inflexible in a number of cases. Some networks require several independent inputs, others require multiple outputs, and some networks have internal\n",
        "branching between layers that makes them look like graphs of layers rather than linear stacks of layers.\n",
        "\n",
        "Some tasks, for instance, require multimodal inputs: they merge data coming from\n",
        "different input sources, processing each type of data using different kinds of neural\n",
        "layers. Imagine a deep-learning model trying to predict the most likely market price of\n",
        "a second-hand piece of clothing, using the following inputs: user-provided metadata\n",
        "(such as the item’s brand, age, and so on), a user-provided text description, and a picture\n",
        "of the item. If you had only the metadata available, you could one-hot encode it\n",
        "and use a densely connected network to predict the price. If you had only the text\n",
        "description available, you could use an RNN or a 1D convnet. If you had only the picture,\n",
        "you could use a 2D convnet. But how can you use all three at the same time? A\n",
        "naive approach would be to train three separate models and then do a weighted average\n",
        "of their predictions. But this may be suboptimal, because the information\n",
        "extracted by the models may be redundant. A better way is to jointly learn a more accurate\n",
        "model of the data by using a model that can see all available input modalities\n",
        "simultaneously: a model with three input branches.\n",
        "\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/multi-input-model.png?raw=1' width='800'/>\n",
        "\n",
        "Similarly, some tasks need to predict multiple target attributes of input data. Given the\n",
        "text of a novel or short story, you might want to automatically classify it by genre (such\n",
        "as romance or thriller) but also predict the approximate date it was written. Of course,\n",
        "you could train two separate models: one for the genre and one for the date. But\n",
        "because these attributes aren’t statistically independent, you could build a better\n",
        "model by learning to jointly predict both genre and date at the same time. Such a\n",
        "joint model would then have two outputs, or heads.\n",
        "\n",
        "Due to correlations\n",
        "between genre and date, knowing the date of a novel would help the model\n",
        "learn rich, accurate representations of the space of novel genres, and vice versa.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/multi-output-model.png?raw=1' width='800'/>\n",
        "\n",
        "Additionally, many recently developed neural architectures require nonlinear network topology: networks structured as directed acyclic graphs. The Inception family of networks (developed by Szegedy et al. at Google),1 for instance, relies on Inception modules, where the input is processed by several parallel convolutional branches whose outputs are then merged back into a single tensor.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/inception-module.png?raw=1' width='800'/>\n",
        "\n",
        "There’s also the recent trend of adding residual connections to a model, which started with the ResNet family of networks. A residual connection consists\n",
        "of reinjecting previous representations into the downstream flow of data by adding a past output tensor to a later output tensor, which helps prevent\n",
        "information loss along the data-processing flow. There are many other examples of such graph-like networks.\n",
        "\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/residual-connection.png?raw=1' width='800'/>\n",
        "\n",
        "These three important use cases—multi-input models, multi-output models, and\n",
        "graph-like models—aren’t possible when using only the Sequential model class in\n",
        "Keras. But there’s another far more general and flexible way to use Keras: the functional API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atpakoDMePCj",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp-4NwO0eW1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Input\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import string\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csj43xvOedow",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to the functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeU1dg74egRd",
        "colab_type": "text"
      },
      "source": [
        "In the functional API, you directly manipulate tensors, and you use layers as functions that take tensors and return tensors (hence, the name functional API):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI8D1LcloG4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor = Input(shape=(32, ))       # A tensor\n",
        "dense = Dense(32, activation='relu')     # A layer is a function\n",
        "output_tensor = dense(input_tensor)      # A layer may be called on a tensor, and it returns a tensor"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvuqG4Q2pQrd",
        "colab_type": "text"
      },
      "source": [
        "Let’s start with a minimal example that shows side by side a simple Sequential model and its equivalent in the functional API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65387duLpGHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "fae98995-c670-4605-8cf3-677521ad2c5b"
      },
      "source": [
        "# Sequential model, which we already know about\n",
        "seq_model = Sequential()\n",
        "seq_model.add(Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(Dense(32, activation='relu'))\n",
        "seq_model.add(Dense(10, activation='softmax'))\n",
        "seq_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmDChA4OppIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7766d70c-b087-4d48-81cc-bab7a8c348f8"
      },
      "source": [
        "input_tensor = Input(shape=(64, )) \n",
        "x = Dense(32, activation='relu')(input_tensor)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "output_tensor = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# The Model class turns an input tensor and output tensor into a model.\n",
        "model = Model(input_tensor, output_tensor)\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS8_ZR3GqiNT",
        "colab_type": "text"
      },
      "source": [
        "The only part that may seem a bit magical at this point is instantiating a Model object using only an input tensor and an output tensor.\n",
        "\n",
        "Behind the scenes, Keras retrieves every layer involved in going from input_tensor to output_tensor, bringing them together into a graph-like data structure—a Model. Of course, the reason it works is that output_tensor was obtained by repeatedly transforming input_tensor. \n",
        "\n",
        "If you tried to build a model from inputs and outputs that weren’t related, you’d get a RuntimeError:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39GuLhHbqOzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "b77f8ce5-80db-458f-ace5-cfc93c841a7f"
      },
      "source": [
        "unrelated_input = Input(shape=(32, ))\n",
        "bad_model = model = Model(unrelated_input, output_tensor)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a682a56a30ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Model must be created under scope of DistStrat it will be trained with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m    172\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 307\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1793\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_3:0\", shape=(None, 64), dtype=float32) at layer \"input_3\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll9rnK5nrB_b",
        "colab_type": "text"
      },
      "source": [
        "This error tells you, in essence, that Keras couldn’t reach input_1 from the provided output tensor.\n",
        "\n",
        "When it comes to compiling, training, or evaluating such an instance of Model, the API is the same as that of Sequential:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYIeWJSuq5ac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "68bcd194-2983-428e-f021-6358f8762759"
      },
      "source": [
        "# Compiles the model\n",
        "model.compile(optimizer='RMSprop', loss='categorical_crossentropy')\n",
        "\n",
        "# Generates dummy Numpy data to train on\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "\n",
        "# Trains the model for 10 epochs\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "# Evaluates the model\n",
        "score = model.evaluate(x_train, y_train)\n",
        "score"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 11.8837\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.3177\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 13.2214\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 14.9566\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.6230\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 20.8913\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 24.4757\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 28.5637\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 32.9192\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 1ms/step - loss: 37.8148\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 40.6706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.670562744140625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drVadp5Br_h-",
        "colab_type": "text"
      },
      "source": [
        "## Multi-input models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psWmUgwGr8RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}