{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-going-beyond-the-sequential-model--keras-functional-api.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMH1Vaftg5276dJwHNBiwDa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-with-python-francois-chollet/blob/7-advanced-deep-learning-best-practices/1_going_beyond_the_sequential_model_keras_functional_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZwz2w4AmLH4",
        "colab_type": "text"
      },
      "source": [
        "# Going beyond the Sequential model: the Keras functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOGAiLt4mOUq",
        "colab_type": "text"
      },
      "source": [
        "Until now, all neural networks introduced in this book have been implemented using the Sequential model. The Sequential model makes the assumption that the\n",
        "network has exactly one input and exactly one output, and that it consists of a linear stack of layers.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/sequential.png?raw=1' width='800'/>\n",
        "\n",
        "This is a commonly verified assumption; the configuration is so common that we’ve been able to cover many topics and practical applications in these pages so far using only the Sequential model class. But this set of assumptions is too inflexible in a number of cases. Some networks require several independent inputs, others require multiple outputs, and some networks have internal\n",
        "branching between layers that makes them look like graphs of layers rather than linear stacks of layers.\n",
        "\n",
        "Some tasks, for instance, require multimodal inputs: they merge data coming from\n",
        "different input sources, processing each type of data using different kinds of neural\n",
        "layers. Imagine a deep-learning model trying to predict the most likely market price of\n",
        "a second-hand piece of clothing, using the following inputs: user-provided metadata\n",
        "(such as the item’s brand, age, and so on), a user-provided text description, and a picture\n",
        "of the item. If you had only the metadata available, you could one-hot encode it\n",
        "and use a densely connected network to predict the price. If you had only the text\n",
        "description available, you could use an RNN or a 1D convnet. If you had only the picture,\n",
        "you could use a 2D convnet. But how can you use all three at the same time? A\n",
        "naive approach would be to train three separate models and then do a weighted average\n",
        "of their predictions. But this may be suboptimal, because the information\n",
        "extracted by the models may be redundant. A better way is to jointly learn a more accurate\n",
        "model of the data by using a model that can see all available input modalities\n",
        "simultaneously: a model with three input branches.\n",
        "\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/multi-input-model.png?raw=1' width='800'/>\n",
        "\n",
        "Similarly, some tasks need to predict multiple target attributes of input data. Given the\n",
        "text of a novel or short story, you might want to automatically classify it by genre (such\n",
        "as romance or thriller) but also predict the approximate date it was written. Of course,\n",
        "you could train two separate models: one for the genre and one for the date. But\n",
        "because these attributes aren’t statistically independent, you could build a better\n",
        "model by learning to jointly predict both genre and date at the same time. Such a\n",
        "joint model would then have two outputs, or heads.\n",
        "\n",
        "Due to correlations\n",
        "between genre and date, knowing the date of a novel would help the model\n",
        "learn rich, accurate representations of the space of novel genres, and vice versa.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/multi-output-model.png?raw=1' width='800'/>\n",
        "\n",
        "Additionally, many recently developed neural architectures require nonlinear network topology: networks structured as directed acyclic graphs. The Inception family of networks (developed by Szegedy et al. at Google),1 for instance, relies on Inception modules, where the input is processed by several parallel convolutional branches whose outputs are then merged back into a single tensor.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/inception-module.png?raw=1' width='800'/>\n",
        "\n",
        "There’s also the recent trend of adding residual connections to a model, which started with the ResNet family of networks. A residual connection consists\n",
        "of reinjecting previous representations into the downstream flow of data by adding a past output tensor to a later output tensor, which helps prevent\n",
        "information loss along the data-processing flow. There are many other examples of such graph-like networks.\n",
        "\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/deep-learning-with-python/residual-connection.png?raw=1' width='800'/>\n",
        "\n",
        "These three important use cases—multi-input models, multi-output models, and\n",
        "graph-like models—aren’t possible when using only the Sequential model class in\n",
        "Keras. But there’s another far more general and flexible way to use Keras: the functional API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atpakoDMePCj",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp-4NwO0eW1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D, LSTM, Embedding, GRU, Bidirectional\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import string\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csj43xvOedow",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to the functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeU1dg74egRd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}